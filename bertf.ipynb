{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":5577,"sourceType":"datasetVersion","datasetId":2518}],"dockerImageVersionId":30664,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-03-03T16:00:25.061835Z","iopub.execute_input":"2024-03-03T16:00:25.062113Z","iopub.status.idle":"2024-03-03T16:00:26.291550Z","shell.execute_reply.started":"2024-03-03T16:00:25.062088Z","shell.execute_reply":"2024-03-03T16:00:26.290578Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"/kaggle/input/youtube/GBvideos.csv\n/kaggle/input/youtube/UScomments.csv\n/kaggle/input/youtube/GB_category_id.json\n/kaggle/input/youtube/US_category_id.json\n/kaggle/input/youtube/GBcomments.csv\n/kaggle/input/youtube/USvideos.csv\n","output_type":"stream"}]},{"cell_type":"code","source":"!pip install transformers -U","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"df=pd.read_csv(\"/kaggle/input/youtube/UScomments.csv\",on_bad_lines='skip',keep_default_na=False)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:11.692230Z","iopub.execute_input":"2024-03-03T16:02:11.693037Z","iopub.status.idle":"2024-03-03T16:02:14.016877Z","shell.execute_reply.started":"2024-03-03T16:02:11.693004Z","shell.execute_reply":"2024-03-03T16:02:14.015822Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_34/1513742586.py:1: DtypeWarning: Columns (2,3) have mixed types. Specify dtype option on import or set low_memory=False.\n  df=pd.read_csv(\"/kaggle/input/youtube/UScomments.csv\",on_bad_lines='skip',keep_default_na=False)\n","output_type":"stream"}]},{"cell_type":"code","source":"df.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:14.387176Z","iopub.execute_input":"2024-03-03T16:02:14.387708Z","iopub.status.idle":"2024-03-03T16:02:14.404628Z","shell.execute_reply.started":"2024-03-03T16:02:14.387678Z","shell.execute_reply":"2024-03-03T16:02:14.403783Z"},"trusted":true},"execution_count":4,"outputs":[{"execution_count":4,"output_type":"execute_result","data":{"text/plain":"      video_id                                       comment_text likes  \\\n0  XpVt6Z1Gjjo                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è     4   \n1  XpVt6Z1Gjjo  I've been following you from the start of your...     3   \n2  XpVt6Z1Gjjo                 Say hi to Kong and maverick for me     3   \n3  XpVt6Z1Gjjo                                MY FAN . attendance     3   \n4  XpVt6Z1Gjjo                                         trending üòâ     3   \n\n  replies  \n0       0  \n1       0  \n2       0  \n3       0  \n4       0  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>video_id</th>\n      <th>comment_text</th>\n      <th>likes</th>\n      <th>replies</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>XpVt6Z1Gjjo</td>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>XpVt6Z1Gjjo</td>\n      <td>I've been following you from the start of your...</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>XpVt6Z1Gjjo</td>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>XpVt6Z1Gjjo</td>\n      <td>MY FAN . attendance</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>XpVt6Z1Gjjo</td>\n      <td>trending üòâ</td>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"df.shape","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:15.522505Z","iopub.execute_input":"2024-03-03T16:02:15.522852Z","iopub.status.idle":"2024-03-03T16:02:15.528603Z","shell.execute_reply.started":"2024-03-03T16:02:15.522822Z","shell.execute_reply":"2024-03-03T16:02:15.527709Z"},"trusted":true},"execution_count":5,"outputs":[{"execution_count":5,"output_type":"execute_result","data":{"text/plain":"(691400, 4)"},"metadata":{}}]},{"cell_type":"code","source":"df1=df['comment_text']\ndf1=df1[:25000]","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:16.716167Z","iopub.execute_input":"2024-03-03T16:02:16.716497Z","iopub.status.idle":"2024-03-03T16:02:16.722800Z","shell.execute_reply.started":"2024-03-03T16:02:16.716470Z","shell.execute_reply":"2024-03-03T16:02:16.721818Z"},"trusted":true},"execution_count":6,"outputs":[]},{"cell_type":"code","source":"df1.head()\n\ndata1=pd.DataFrame(df1)\n\ndata1.head()\n\ndata1.rename(columns = {'comment_text':'Comment'}, inplace = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:18.264060Z","iopub.execute_input":"2024-03-03T16:02:18.264839Z","iopub.status.idle":"2024-03-03T16:02:18.271371Z","shell.execute_reply.started":"2024-03-03T16:02:18.264803Z","shell.execute_reply":"2024-03-03T16:02:18.270556Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"from nltk.sentiment.vader import SentimentIntensityAnalyzer\nimport nltk\n\nnltk.download('vader_lexicon')\nsentiments = SentimentIntensityAnalyzer()\ndata1[\"Positive\"] = [sentiments.polarity_scores(str(i))[\"pos\"] for i in data1[\"Comment\"]]\ndata1[\"Negative\"] = [sentiments.polarity_scores(str(i))[\"neg\"] for i in data1[\"Comment\"]]\ndata1[\"Neutral\"] = [sentiments.polarity_scores(str(i))[\"neu\"] for i in data1[\"Comment\"]]\ndata1['Compound'] = [sentiments.polarity_scores(str(i))[\"compound\"] for i in data1[\"Comment\"]]\n\nscore = data1[\"Compound\"].values\nsentiment = []\nfor i in score:\n    if i >= 0.05 :\n        sentiment.append('Positive')\n    elif i <= -0.05 :\n        sentiment.append('Negative')\n    else:\n        sentiment.append('Neutral')\ndata1[\"Sentiment\"] = sentiment\ndata1.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:02:39.547128Z","iopub.execute_input":"2024-03-03T16:02:39.547792Z","iopub.status.idle":"2024-03-03T16:03:04.158516Z","shell.execute_reply.started":"2024-03-03T16:02:39.547749Z","shell.execute_reply":"2024-03-03T16:03:04.157543Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/nltk/twitter/__init__.py:20: UserWarning: The twython library has not been installed. Some functionality from the twitter package will not be available.\n  warnings.warn(\"The twython library has not been installed. \"\n","output_type":"stream"},{"name":"stdout","text":"[nltk_data] Downloading package vader_lexicon to\n[nltk_data]     /usr/share/nltk_data...\n[nltk_data]   Package vader_lexicon is already up-to-date!\n","output_type":"stream"},{"execution_count":8,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Positive  Negative  \\\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è     0.000       0.0   \n1  I've been following you from the start of your...     0.000       0.0   \n2                 Say hi to Kong and maverick for me     0.000       0.0   \n3                                MY FAN . attendance     0.603       0.0   \n4                                         trending üòâ     0.000       0.0   \n\n   Neutral  Compound Sentiment  \n0    1.000    0.0000   Neutral  \n1    1.000    0.0000   Neutral  \n2    1.000    0.0000   Neutral  \n3    0.397    0.4648  Positive  \n4    1.000    0.0000   Neutral  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Positive</th>\n      <th>Negative</th>\n      <th>Neutral</th>\n      <th>Compound</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n      <td>0.603</td>\n      <td>0.0</td>\n      <td>0.397</td>\n      <td>0.4648</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n      <td>0.000</td>\n      <td>0.0</td>\n      <td>1.000</td>\n      <td>0.0000</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"data2=data1.drop(['Positive','Negative','Neutral','Compound'],axis=1)\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:03:04.160246Z","iopub.execute_input":"2024-03-03T16:03:04.161119Z","iopub.status.idle":"2024-03-03T16:03:04.175717Z","shell.execute_reply.started":"2024-03-03T16:03:04.161084Z","shell.execute_reply":"2024-03-03T16:03:04.174803Z"},"trusted":true},"execution_count":9,"outputs":[{"execution_count":9,"output_type":"execute_result","data":{"text/plain":"                                             Comment Sentiment\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è   Neutral\n1  I've been following you from the start of your...   Neutral\n2                 Say hi to Kong and maverick for me   Neutral\n3                                MY FAN . attendance  Positive\n4                                         trending üòâ   Neutral","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>Neutral</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n      <td>Positive</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n      <td>Neutral</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.preprocessing import LabelEncoder\n\nle = LabelEncoder()\ndata2['Sentiment'] = le.fit_transform(data2['Sentiment'])\ndata2.head()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:03:10.816919Z","iopub.execute_input":"2024-03-03T16:03:10.817564Z","iopub.status.idle":"2024-03-03T16:03:10.837105Z","shell.execute_reply.started":"2024-03-03T16:03:10.817524Z","shell.execute_reply":"2024-03-03T16:03:10.836075Z"},"trusted":true},"execution_count":10,"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"                                             Comment  Sentiment\n0                  Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è          1\n1  I've been following you from the start of your...          1\n2                 Say hi to Kong and maverick for me          1\n3                                MY FAN . attendance          2\n4                                         trending üòâ          1","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Comment</th>\n      <th>Sentiment</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Logan Paul it's yo big day ‚ÄºÔ∏è‚ÄºÔ∏è‚ÄºÔ∏è</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>I've been following you from the start of your...</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Say hi to Kong and maverick for me</td>\n      <td>1</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>MY FAN . attendance</td>\n      <td>2</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>trending üòâ</td>\n      <td>1</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"import numpy as np\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.metrics import accuracy_score, recall_score, precision_score, f1_score\nimport torch\nfrom transformers import TrainingArguments, Trainer\nfrom transformers import BertTokenizer, BertForSequenceClassification","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:03:12.430303Z","iopub.execute_input":"2024-03-03T16:03:12.430613Z","iopub.status.idle":"2024-03-03T16:03:30.715444Z","shell.execute_reply.started":"2024-03-03T16:03:12.430587Z","shell.execute_reply":"2024-03-03T16:03:30.714687Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stderr","text":"2024-03-03 16:03:21.702806: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:9261] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n2024-03-03 16:03:21.702911: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:607] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n2024-03-03 16:03:21.875734: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1515] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import BertTokenizer, BertForSequenceClassification\ntokenizer = BertTokenizer.from_pretrained('bert-base-uncased')\nmodel = BertForSequenceClassification.from_pretrained('bert-base-uncased',num_labels=3)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:03:30.716803Z","iopub.execute_input":"2024-03-03T16:03:30.717301Z","iopub.status.idle":"2024-03-03T16:03:34.301175Z","shell.execute_reply.started":"2024-03-03T16:03:30.717276Z","shell.execute_reply":"2024-03-03T16:03:34.300337Z"},"trusted":true},"execution_count":12,"outputs":[{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/48.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e551902a2d23433284c3581887ab9edd"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"52379f180239476d99598de8f2a21405"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/466k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0b487f2154b428b95aa0284807f4a49"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/570 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"11faba4cc8764929b1f1bf9f2bcee42b"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/440M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"fa4015a028a948c8b7dfffefe573faea"}},"metadata":{}},{"name":"stderr","text":"Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-base-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\nYou should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n","output_type":"stream"}]},{"cell_type":"code","source":"X = list(data2['Comment'])\ny = list(data2['Sentiment'])\nX_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2,stratify=y)\n# print(X_train)\nX_train_tokenized = tokenizer(X_train, padding=True, truncation=True, max_length=512)\nX_val_tokenized = tokenizer(X_val, padding=True, truncation=True, max_length=512)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:04:06.996933Z","iopub.execute_input":"2024-03-03T16:04:06.997768Z","iopub.status.idle":"2024-03-03T16:04:23.774200Z","shell.execute_reply.started":"2024-03-03T16:04:06.997721Z","shell.execute_reply":"2024-03-03T16:04:23.773175Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"print(X_train_tokenized['attention_mask'][0])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:04:23.775794Z","iopub.execute_input":"2024-03-03T16:04:23.776101Z","iopub.status.idle":"2024-03-03T16:04:23.781048Z","shell.execute_reply.started":"2024-03-03T16:04:23.776075Z","shell.execute_reply":"2024-03-03T16:04:23.780110Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n","output_type":"stream"}]},{"cell_type":"code","source":"# Create torch dataset\nclass Dataset(torch.utils.data.Dataset):\n    def __init__(self, encodings, labels=None):\n        self.encodings = encodings\n        self.labels = labels\n\n    def __getitem__(self, idx):\n        item = {key: torch.tensor(val[idx]) for key, val in self.encodings.items()}\n        if self.labels:\n            item[\"labels\"] = torch.tensor(self.labels[idx])\n        return item\n\n    def __len__(self):\n        return len(self.encodings[\"input_ids\"])","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:05:25.654896Z","iopub.execute_input":"2024-03-03T16:05:25.655512Z","iopub.status.idle":"2024-03-03T16:05:25.661931Z","shell.execute_reply.started":"2024-03-03T16:05:25.655481Z","shell.execute_reply":"2024-03-03T16:05:25.661007Z"},"trusted":true},"execution_count":15,"outputs":[]},{"cell_type":"code","source":"train_dataset = Dataset(X_train_tokenized, y_train)\nval_dataset = Dataset(X_val_tokenized, y_val)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:05:26.859448Z","iopub.execute_input":"2024-03-03T16:05:26.859796Z","iopub.status.idle":"2024-03-03T16:05:26.864242Z","shell.execute_reply.started":"2024-03-03T16:05:26.859745Z","shell.execute_reply":"2024-03-03T16:05:26.863200Z"},"trusted":true},"execution_count":16,"outputs":[]},{"cell_type":"code","source":"train_dataset[5]","metadata":{"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# def compute_metrics(p):\n#     print(type(p))\n#     pred, labels = p\n#     pred = np.argmax(pred, axis=1)\n\n#     accuracy = accuracy_score(y_true=labels, y_pred=pred)\n#     recall = recall_score(y_true=labels, y_pred=pred)\n#     precision = precision_score(y_true=labels, y_pred=pred)\n#     f1 = f1_score(y_true=labels, y_pred=pred)\n\n#     return {\"accuracy\": accuracy, \"precision\": precision, \"recall\": recall, \"f1\": f1}","metadata":{"execution":{"iopub.status.busy":"2024-02-28T18:15:30.327007Z","iopub.execute_input":"2024-02-28T18:15:30.327370Z","iopub.status.idle":"2024-02-28T18:15:30.333837Z","shell.execute_reply.started":"2024-02-28T18:15:30.327345Z","shell.execute_reply":"2024-02-28T18:15:30.332602Z"},"trusted":true},"execution_count":43,"outputs":[]},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, precision_recall_fscore_support\n\ndef compute_metrics(pred):\n    # Extract true labels from the input object\n    labels = pred.label_ids\n    \n    # Obtain predicted class labels by finding the column index with the maximum probability\n    preds = pred.predictions.argmax(-1)\n    \n    # Compute macro precision, recall, and F1 score using sklearn's precision_recall_fscore_support function\n    precision, recall, f1, _ = precision_recall_fscore_support(labels, preds, average='macro')\n    \n    # Calculate the accuracy score using sklearn's accuracy_score function\n    acc = accuracy_score(labels, preds)\n    \n    # Return the computed metrics as a dictionary\n    return {\n        'Accuracy': acc,\n        'F1': f1,\n        'Precision': precision,\n        'Recall': recall\n    }","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:05:42.589354Z","iopub.execute_input":"2024-03-03T16:05:42.590208Z","iopub.status.idle":"2024-03-03T16:05:42.596364Z","shell.execute_reply.started":"2024-03-03T16:05:42.590175Z","shell.execute_reply":"2024-03-03T16:05:42.595444Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"code","source":"# Define Trainer\nargs = TrainingArguments(\n    output_dir=\"output\",\n    num_train_epochs=6,\n    per_device_train_batch_size=8\n\n)\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=val_dataset,\n    compute_metrics=compute_metrics\n)\n     ","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:10:12.236226Z","iopub.execute_input":"2024-03-03T16:10:12.237042Z","iopub.status.idle":"2024-03-03T16:10:12.257000Z","shell.execute_reply.started":"2024-03-03T16:10:12.237012Z","shell.execute_reply":"2024-03-03T16:10:12.255445Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"code","source":"trainer.train()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T16:10:13.438431Z","iopub.execute_input":"2024-03-03T16:10:13.439057Z","iopub.status.idle":"2024-03-03T17:52:44.896994Z","shell.execute_reply.started":"2024-03-03T16:10:13.439016Z","shell.execute_reply":"2024-03-03T17:52:44.895834Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='7500' max='7500' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [7500/7500 1:42:29, Epoch 6/6]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Step</th>\n      <th>Training Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>500</td>\n      <td>0.504000</td>\n    </tr>\n    <tr>\n      <td>1000</td>\n      <td>0.351500</td>\n    </tr>\n    <tr>\n      <td>1500</td>\n      <td>0.278600</td>\n    </tr>\n    <tr>\n      <td>2000</td>\n      <td>0.227100</td>\n    </tr>\n    <tr>\n      <td>2500</td>\n      <td>0.212500</td>\n    </tr>\n    <tr>\n      <td>3000</td>\n      <td>0.137900</td>\n    </tr>\n    <tr>\n      <td>3500</td>\n      <td>0.135500</td>\n    </tr>\n    <tr>\n      <td>4000</td>\n      <td>0.112600</td>\n    </tr>\n    <tr>\n      <td>4500</td>\n      <td>0.075500</td>\n    </tr>\n    <tr>\n      <td>5000</td>\n      <td>0.088900</td>\n    </tr>\n    <tr>\n      <td>5500</td>\n      <td>0.040700</td>\n    </tr>\n    <tr>\n      <td>6000</td>\n      <td>0.042400</td>\n    </tr>\n    <tr>\n      <td>6500</td>\n      <td>0.037400</td>\n    </tr>\n    <tr>\n      <td>7000</td>\n      <td>0.012400</td>\n    </tr>\n    <tr>\n      <td>7500</td>\n      <td>0.012000</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"execution_count":22,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=7500, training_loss=0.1512724810918172, metrics={'train_runtime': 6150.6522, 'train_samples_per_second': 19.51, 'train_steps_per_second': 1.219, 'total_flos': 3.157361012736e+16, 'train_loss': 0.1512724810918172, 'epoch': 6.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.evaluate()","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:52:52.829783Z","iopub.execute_input":"2024-03-03T17:52:52.830140Z","iopub.status.idle":"2024-03-03T17:54:24.635171Z","shell.execute_reply.started":"2024-03-03T17:52:52.830112Z","shell.execute_reply":"2024-03-03T17:54:24.634019Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/torch/nn/parallel/_functions.py:68: UserWarning: Was asked to gather along dimension 0, but all input tensors were scalars; will instead unsqueeze and return a vector.\n  warnings.warn('Was asked to gather along dimension 0, but all '\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='313' max='313' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [313/313 01:31]\n    </div>\n    "},"metadata":{}},{"execution_count":23,"output_type":"execute_result","data":{"text/plain":"{'eval_loss': 0.5562778115272522,\n 'eval_Accuracy': 0.9186,\n 'eval_F1': 0.9108712834999483,\n 'eval_Precision': 0.9139693745802626,\n 'eval_Recall': 0.9080708150082802,\n 'eval_runtime': 91.7947,\n 'eval_samples_per_second': 54.469,\n 'eval_steps_per_second': 3.41,\n 'epoch': 6.0}"},"metadata":{}}]},{"cell_type":"code","source":"model_path=\"Bert-Youtube\"\ntrainer.save_model(model_path)\ntokenizer.save_pretrained(model_path)","metadata":{"execution":{"iopub.status.busy":"2024-03-03T17:57:22.166151Z","iopub.execute_input":"2024-03-03T17:57:22.166501Z","iopub.status.idle":"2024-03-03T17:57:23.194633Z","shell.execute_reply.started":"2024-03-03T17:57:22.166471Z","shell.execute_reply":"2024-03-03T17:57:23.193646Z"},"trusted":true},"execution_count":26,"outputs":[{"execution_count":26,"output_type":"execute_result","data":{"text/plain":"('Bert-Youtube/tokenizer_config.json',\n 'Bert-Youtube/special_tokens_map.json',\n 'Bert-Youtube/vocab.txt',\n 'Bert-Youtube/added_tokens.json')"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}